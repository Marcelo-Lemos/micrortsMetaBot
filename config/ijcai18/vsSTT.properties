# Train for 100 matches

# -------------- microRTS settings -----------------
launch_mode=STANDALONE

map_location=maps/24x24/basesWorkers24x24.xml

num_games=100

max_cycles=3000

partially_observable=false

# Versions of the Unit Type Table (DEFAULT = 2)
# 1 = original
# 2 = original finetuned
# 3 = non-deterministic version of original finetuned (damages are random)
UTT_version=2

# Conflict policies (DEFAULT = 1)
# 1 = A conflict resolution policy where move conflicts cancel both moves
# 2 = A conflict resolution policy where move conflicts are solved randomly
# 3 = A conflict resolution policy where move conflicts are solved by alternating the units trying to move
conflict_policy=1

# a file to write match results
runner.output=summary.csv

### STANDALONE Settings ###
# Only needed if mode is STANDALONE
# Set which AIs will play
AI1=metabot.MetaBot
AI2=standard.StrategyTactics

### metabot settings ### (this same file)
player1.config=config/ijcai18/vsSTT.properties

# -------------- MetaBot settings -----------------
# specifies the portfolio members
portfolio.members = WorkerRush, LightRush, RangedRush, HeavyRush, Expand, BuildBarracks

### the parameters below are related to the reinforcement learning algorithm ###
# specifies the type of learning agent
rl.agent = "sarsa"

# the initial value of exploration rate
rl.epsilon.initial = 0.1

# epsilon is multiplied by this decay factor after each episode. 
# setting as 1 makes epsilon constant
rl.epsilon.decay = 0.9984

# the initial value of learning rate
rl.alpha.initial = 0.0001

# alpha is multiplied by this decay factor after each episode. 
# setting as 1 makes alpha constant
rl.alpha.decay = 1

# the discount factor
rl.gamma = 0.9

# the eligibility trace (not used yet)
rl.lambda = 0

# the feature extractor
rl.feature.extractor = quadrant_model

# the map is divided in quadrant_division x quadrant_division quadrants
# this parameter is specific of the quadrant_model
rl.feature.extractor.quadrant_division = 3

# the random seed (if not specified, it will load the default seed)
rl.random.seed = 1

# the prefix of the output file to save weights in binary format
rl.output.binprefix = training/ijcai18_b

# the prefix of the output file to save weights in human-readable format
#rl.output.humanprefix = training/vslight